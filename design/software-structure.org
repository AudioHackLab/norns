#+TITLE: norns - software architecture

* about this document

** history

| version |       date | author |
|---------+------------+--------|
|   0.0.0 | 2017-01-22 | emb    |

** intent

 this document proposes a preliminary high-level software design for *norns*. its goal is to outline a broad plan for code module separation and identify some of the 3rd-party technologies to use. we do not expect every implementation choice to remain unchanged.

 this document can be updated to reflect architecture changes as we approach version 1.0.0.

* overview of functionality.

 *norns* is an audio processing hardware and software package, built on raspberry pi and linux.


primary features of *norns*:

- provide the user with an interpreted programming environment (Lua) for soft-realtime control of audio processing

- enable remote execution of user code on the fly

- change/reroute audio modules on the fly

- provide an "easy" path to development of new audio modules

- integrate with a wide variety of controller hardware

functionality is divided into three main areas, which may or may not correspond to separate processes/applications, but which shall certainly be implemented as distinct code modules.

** *maiden*

 controller: provides the user interface, chooses user code to be executed, and communicates with remote hosts. 

 initially, it will provide a text-only interface for terminal access using ~ncurses~. 

 future iterations could do other things:
- serve a web app via HTTP
- provide a REST API over HTTP for a client side app
- something else?


** *matron*

 interpreter: maintains Lua state, executes user code, and glues the interpreted environment to everything else:
- input from *maiden*  (user code, but maybe other things too
- output to *crone*  (change audio modules, parameters, buffers, &c)
- I/O to and from onboard hardware (encoders, switches, screen)
- I/O to and from USB peripherals (grids, MIDI, HID)
- other hardware? (i2c? serial?)

** *crone*

 audio host.
- swaps audio 'modules' ('instruments'? 'engines'?)
- manipulates processing parameters
- loads and stores sound files
- can receive and transmit audio buffer data

 the initial implementation will be in Supercollider and communicate with *matron* using OSC.

 for future iterations, we are considering implementing an [[http://lv2plug.in][LV2]] host, likely based on the [[https://github.com/moddevices/mod-host][MOD devices]] codebase. 

* software architecture

 here is an informal flowchart / code module layout. it does not mean to describe data or dependency flow in detail, only to suggest technologies, libraries, project structure and tasks required for a working prototype.

#+BEGIN_SRC dot :file norns_structure_legend.svg :cmdline -Kdot -Tsvg
digraph {
node[shape=box];
//subgraph cluster_legend {
//    label="legend";
    norns[label="norns code", color=blue, style=bold];
    external[label="external libraries / programs"];
    resources[label="system resources", style=dashed];
//}
}
#+END_SRC
#+RESULTS:
[[file:norns_structure_legend.svg]]

#+BEGIN_SRC dot :file norns_structure.svg :cmdline -Kdot -Tsvg
digraph {
	layout=dot;
	node[shape=box];
	splines=line;
	concentrate=true;

	subgraph norns_code {
		node[color=blue, style=bold];

		ctl [label="control logic"];
        ui [label="UI"];

		weaver [label="weaver.h"];
		lua[label="lua interface"];

        timers;
		gpio;
		screen;

		oracle [label="oracle.h"];
		sc[label="sclang classes"];
	}

	subgraph ext_libs {
		libmonome;
		libevdev[label="libevdev/SDL"];
		liblua;
		MIDI;
		sclang;
		scsynth;
	}

	subgraph resources {
		node[style="dashed"];
		
		remote [label="remote host (ssh)"];
		shmem [label="shared memory"];
		files[label="local filesystem"];
		sock[label="datagram socket"];
	}

	subgraph cluster_norns {
		
		label="norns, software flowchart";

		splines=line;
		concentrate=true;
	
		subgraph cluster_maiden {
			label="controller (maiden)";
			ctl;
            ui;
			ncurses;	
		}

		remote;
		shmem;
		files;
		sock;
		
		subgraph cluster_matron {
			label="interpreter (matron)";
			// inputs
			weaver;
			libevdev;
            MIDI;
			gpio;			
			libmonome;
			// interpreter
			lua;
			liblua;
            timers;
			// outputs
			screen;
			liblo;
		    oracle;
		}

		subgraph cluster_crone {
			label="audio engine (crone)";
			sc;
			{ 
				//rank = same;
				sclang;
				scsynth;
			}
		}
	}

	// connections
	files -> ctl;
	//[label="(inotify)"];
	ctl -> shmem;
	ctl -> ui -> ctl;
    ui -> ncurses -> ui;
	ncurses -> remote;
	remote -> ncurses;

	// lua econnections
	shmem -> weaver;
	weaver -> lua;
	libevdev -> lua;
	gpio -> lua -> gpio;
	MIDI -> lua -> MIDI;
	libmonome -> lua -> libmonome;
	lua -> liblua -> lua;
    lua -> timers -> lua;
	lua -> screen;
	lua -> oracle -> liblo;
	liblo -> oracle -> lua;

	// sc connections
	liblo -> sock -> sc;
	sc -> sock -> liblo;
	sc -> sclang;
	sclang -> scsynth -> sclang;

}
#+END_SRC

#+RESULTS:
[[file:norns_structure.svg]]

* implementation notes

** IPC

in the figure above, the header files ~oracle.h~ and ~weaver.h~ are referenced. this is just to emphasise that each channel of interprocess communication should be handled through a "black box" API. 

for example: here we specify the use of shared memory between controller and interpreter, but in the final implementation we may want to allow *maiden* to run remotely, making serial communication a better choice. 

so, these dedicated headers will specify interprocess /protocols/, while keeping the transport layer decoupled. it would be great to generate them directly from a protocol spec.

** audio buffers

one requested feature is the ability to manipulate audio buffers from user code. ideally, this feature would be implemented using shared memory between interpreter and processor; in practice, this may prove challenging. it may be possible to used shared memory between an LV2 host and its plugins, but for supercollider such an exchange can only be acheived asynchronously with a sequence of OSC packets (or by considerable hacking on the scsynth codebase.)

in any case, direct transmission of audio buffer data will be part of the API described by ~oracle.h~, as well as functions to move audio between *crone* and the filesystem. 

** MIDI

it's not yet clear how we should pass MIDI through the interpreter. it may be impossible to provide sample-accurate events in that circumstance. we could do one or more of the following:
- *matron* interacts directly with e.g. ~/dev/sequencer~. fine for coarse time resolution / sparse events.
- *matron* registers as an ALSA or JACK client and receives MIDI event buffers.
- user code can pass MIDI handling over to the audio server somehow (and define logic/transformation? hm), allowing sample-accurate performance.

** timing resolution

as the above section implies, there is some uncertainty about how close to "realtime" the interpreted code can get. (to diagnose this, implementing glue between Lua and (say) POSIX timers should be an early order of business.)

but with Supercollider as the engine, we are inherently limited to the sample block rate, as far as how often parameter changes are interpreted. in addition, the OSC/UDP connection has limited bandwidth (but maybe enough to make no significant difference, except for arbitrarily large buffer transactions.)

if we do end up switching to LV2, we can use shared memory (greater bandwidth), and even schedule timestamped events within a sample block.

** HID

there are a number of competing solutions for getting input from HID devices such as gamepads. ~libevdev~ is a contemporary alternative to ~libudev~ for getting low-level events. but initially we might use a higher-level library like ~SDL2~, just to take some of the pain out of device management. 

* next steps

this document does not describe:

- specific features and API for *crone* 

- specific features and API for *matron*

- UI design for *maiden*

these topics should be addressed separately, and relatively soon. for the moment we can assume some basic, obvious features, and begin implementation with those...
